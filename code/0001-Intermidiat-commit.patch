From c225ffa255a51da900672c96c4d91f3ffa5ee6a1 Mon Sep 17 00:00:00 2001
From: Sidraya <sidraya.jayagond@ibm.com>
Date: Mon, 5 Jun 2023 17:02:23 +0000
Subject: [PATCH] Intermidiat commit

---
 src/hotspot/cpu/s390/downcallLinker_s390.cpp  | 321 +++++++++++++++++-
 src/hotspot/cpu/s390/foreignGlobals_s390.cpp  | 232 ++++++++++++-
 src/hotspot/cpu/s390/foreignGlobals_s390.hpp  |  19 +-
 src/hotspot/cpu/s390/frame_s390.cpp           |  27 +-
 src/hotspot/cpu/s390/frame_s390.inline.hpp    |   5 +
 src/hotspot/cpu/s390/methodHandles_s390.cpp   |  11 +-
 src/hotspot/cpu/s390/vmstorage_s390.hpp       |  63 +++-
 .../classes/jdk/internal/foreign/CABI.java    |   7 +-
 .../internal/foreign/abi/AbstractLinker.java  |   4 +-
 .../jdk/internal/foreign/abi/SharedUtils.java |   2 +
 .../foreign/abi/s390/S390Architecture.java    | 148 ++++++++
 .../abi/s390/linux/LinuxS390CallArranger.java | 308 +++++++++++++++++
 .../abi/s390/linux/LinuxS390Linker.java       |  64 ++++
 .../foreign/abi/s390/linux/TypeClass.java     | 137 ++++++++
 .../compiler/TestLinkToNativeRBP.java         |   2 +-
 .../platform/PlatformLayouts.java             |  54 +++
 16 files changed, 1374 insertions(+), 30 deletions(-)
 create mode 100644 src/java.base/share/classes/jdk/internal/foreign/abi/s390/S390Architecture.java
 create mode 100644 src/java.base/share/classes/jdk/internal/foreign/abi/s390/linux/LinuxS390CallArranger.java
 create mode 100644 src/java.base/share/classes/jdk/internal/foreign/abi/s390/linux/LinuxS390Linker.java
 create mode 100644 src/java.base/share/classes/jdk/internal/foreign/abi/s390/linux/TypeClass.java

diff --git a/src/hotspot/cpu/s390/downcallLinker_s390.cpp b/src/hotspot/cpu/s390/downcallLinker_s390.cpp
index baee7d7a043..5d95dd7c8a8 100644
--- a/src/hotspot/cpu/s390/downcallLinker_s390.cpp
+++ b/src/hotspot/cpu/s390/downcallLinker_s390.cpp
@@ -1,5 +1,5 @@
 /*
- * Copyright (c) 2022, 2023, Oracle and/or its affiliates. All rights reserved.
+ * Copyright (c) 2022, Oracle and/or its affiliates. All rights reserved.
  * Copyright (c) 2020, Red Hat, Inc. All rights reserved.
  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
  *
@@ -23,8 +23,75 @@
  */
 
 #include "precompiled.hpp"
+#include "asm/macroAssembler.inline.hpp"
+#include "code/codeBlob.hpp"
+#include "code/codeCache.hpp"
+#include "code/vmreg.inline.hpp"
+#include "compiler/oopMap.hpp"
+#include "logging/logStream.hpp"
+#include "memory/resourceArea.hpp"
 #include "prims/downcallLinker.hpp"
-#include "utilities/debug.hpp"
+#include "runtime/globals.hpp"
+#include "runtime/stubCodeGenerator.hpp"
+
+#define __ _masm->
+class DowncallStubGenerator : public StubCodeGenerator {
+  BasicType* _signature;
+  int _num_args;
+  BasicType _ret_bt;
+  const ABIDescriptor& _abi;
+
+  const GrowableArray<VMStorage>&  _input_registers;
+  const GrowableArray<VMStorage>&  _output_registers;
+
+  bool _needs_return_buffer;
+  int _captured_state_mask;
+  bool _needs_transition;  
+
+  int _frame_complete;
+  int _frame_size_slots;
+  OopMapSet* _oop_maps;
+public:
+  DowncallStubGenerator(CodeBuffer* buffer,
+		         BasicType* signature,
+			 int num_args,
+			 BasicType ret_bt,
+			 const ABIDescriptor& abi,
+			 const GrowableArray<VMStorage>& input_registers,
+			 const GrowableArray<VMStorage>& output_registers,
+			 bool needs_return_buffer,
+			 int captured_state_mask,
+			 bool needs_transition)
+  :StubCodeGenerator(buffer, PrintMethodHandleStubs),
+     _signature(signature),
+     _num_args(num_args),
+     _ret_bt(ret_bt),
+     _abi(abi),
+     _input_registers(input_registers),
+     _output_registers(output_registers),
+     _needs_return_buffer(needs_return_buffer),
+     _captured_state_mask(captured_state_mask),
+     _needs_transition(needs_transition),	
+     _frame_complete(0),
+     _frame_size_slots(0),
+     _oop_maps(NULL) {
+  }
+  void generate();
+  int frame_complete() const {
+    return _frame_complete;
+  }
+
+  int framesize() const {
+    return (_frame_size_slots >> (LogBytesPerWord - LogBytesPerInt));
+  }
+
+  OopMapSet* oop_maps() const {
+   return _oop_maps;
+  }
+};
+
+static const int native_invoker_code_base_size = 384;
+static const int native_invoker_size_per_args = 8;
 
 RuntimeStub* DowncallLinker::make_downcall_stub(BasicType* signature,
                                                 int num_args,
@@ -34,7 +101,251 @@ RuntimeStub* DowncallLinker::make_downcall_stub(BasicType* signature,
                                                 const GrowableArray<VMStorage>& output_registers,
                                                 bool needs_return_buffer,
                                                 int captured_state_mask,
-                                                bool needs_transition) {
-  Unimplemented();
-  return nullptr;
+						bool needs_transition) {
+
+  int code_size = native_invoker_code_base_size + (num_args * native_invoker_size_per_args);
+  int locs_size = 1; //must be non zero
+  CodeBuffer code("nep_invoker_blob", code_size, locs_size);
+
+  DowncallStubGenerator g(&code, signature, num_args, ret_bt, abi,
+                          input_registers, output_registers,
+                          needs_return_buffer, captured_state_mask,
+			  needs_transition);
+ g.generate();
+ code.log_section_sizes("nep_invoker_blob");
+
+  RuntimeStub* stub =
+    RuntimeStub::new_runtime_stub("nep_invoker_blob",
+                                  &code,
+                                  g.frame_complete(),
+                                  g.framesize(),
+                                  g.oop_maps(), false);
+
+#ifndef PRODUCT
+  LogTarget(Trace, foreign, downcall) lt;
+  if (lt.is_enabled()) {
+    ResourceMark rm;
+    LogStream ls(lt);
+    stub->print_on(&ls);
+  }
+#endif
+
+  return stub;
+}
+
+void DowncallStubGenerator::generate() {
+  Register call_target_address = Z_R1_scratch,
+	   callerSP = Z_tmp_1,
+	   tmp = Z_R0_scratch;
+
+  VMStorage shuffle_reg = _abi._scratch1;
+
+  JavaCallingConvention in_conv;
+  NativeCallingConvention out_conv(_input_registers);
+  ArgumentShuffle arg_shuffle(_signature, _num_args, _signature, _num_args, &in_conv, &out_conv, shuffle_reg);
+
+ #ifndef PRODUCT
+  LogTarget(Trace, foreign, downcall) lt;
+  if (lt.is_enabled()) {
+    ResourceMark rm;
+    LogStream ls(lt);
+    arg_shuffle.print_on(&ls);
+  }
+#endif
+
+  int allocated_frame_size = 0;
+  assert(_abi._shadow_space_bytes == frame::z_abi_160_size, "expected space according to ABI");
+  allocated_frame_size = frame::z_abi_160_size;
+  allocated_frame_size += arg_shuffle.out_arg_bytes();  
+
+  bool should_save_return_value = !_needs_return_buffer && _needs_transition;;
+  RegSpiller out_reg_spiller(_output_registers);
+  int spill_offset = -1;   
+
+  if (should_save_return_value) {
+    spill_offset = allocated_frame_size;
+    // spill area can be shared with shadow space and out args,
+    // since they are only used before the call,
+    // and spill area is only used after.
+    allocated_frame_size += BytesPerWord;
+    allocated_frame_size = out_reg_spiller.spill_size_bytes() > allocated_frame_size
+                           ? out_reg_spiller.spill_size_bytes()
+                           : allocated_frame_size;
+  }
+
+  StubLocations locs;
+  locs.set(StubLocations::TARGET_ADDRESS, _abi._scratch2);
+  assert(as_Register(_abi._scratch2) == as_Register(locs.get(StubLocations::TARGET_ADDRESS)), "required by SId");
+  if (_needs_return_buffer) {
+    locs.set_frame_data(StubLocations::RETURN_BUFFER, allocated_frame_size);
+    allocated_frame_size += BytesPerWord;
+  }
+  if (_captured_state_mask != 0) {
+     __ block_comment("{ _captured_state_mask is set");
+    locs.set_frame_data(StubLocations::CAPTURED_STATE_BUFFER, allocated_frame_size);
+    allocated_frame_size += BytesPerWord;
+     __ block_comment("} _captured_state_mask is set");
+  }
+
+  allocated_frame_size = align_up(allocated_frame_size, 8);
+  _frame_size_slots = allocated_frame_size >> LogBytesPerInt;  
+
+  _oop_maps  = _needs_transition ? new OopMapSet() : nullptr;  
+  address start = __ pc();
+
+  __ save_return_pc();
+  __ z_lgr(callerSP, Z_SP);
+  __ push_frame(allocated_frame_size, tmp);                     // Create a new frame for the wrapper.
+  
+  _frame_complete = __ pc() - start;
+
+  address the_pc = __ pc();
+
+  if (_needs_transition) {
+  __ block_comment("{ thread java2native");
+  __ get_PC(tmp);
+  __ set_last_Java_frame(Z_SP, tmp);
+
+  OopMap* map = new OopMap(_frame_size_slots, 0);
+  _oop_maps->add_gc_map(the_pc - start, map);  
+
+  // State transition
+  __ set_thread_state(_thread_in_native);
+  __ block_comment("} thread java2native");
+  }
+  __ block_comment("{ argument shuffle");
+  arg_shuffle.generate(_masm, as_VMStorage(callerSP), frame::z_jit_out_preserve_size, _abi._shadow_space_bytes, locs);
+  __ block_comment("} argument shuffle");
+
+  __ call(as_Register(locs.get(StubLocations::TARGET_ADDRESS)));
+
+  if (_needs_return_buffer)
+  {
+    // Store return values as required by BoxBindingCalculator.
+    __ z_lg(Z_R1_scratch, Address(Z_SP, locs.data_offset(StubLocations::RETURN_BUFFER)));
+    int offset = 0;
+    for (int i = 0; i < _output_registers.length(); i++)
+    {
+      VMStorage reg = _output_registers.at(i);
+      if (reg.type() == StorageType::INTEGER)
+      {
+          __ z_stg(as_Register(reg), Address(Z_R1_scratch, offset));
+          offset += 8;
+      }
+      else if (reg.type() == StorageType::FLOAT)
+      {
+          __ z_std(as_FloatRegister(reg), Address(Z_R1_scratch, offset));
+          offset += 8;
+      }
+      else
+      {
+        ShouldNotReachHere();
+      }
+    }
+  }
+
+  //////////////////////////////////////////////////////////////////////////////
+
+  if (_captured_state_mask != 0) {
+    __ block_comment("{ save thread local");
+
+    if (should_save_return_value) {
+      out_reg_spiller.generate_spill(_masm, spill_offset);
+    }
+
+    __ load_const_optimized(call_target_address, CAST_FROM_FN_PTR(uint64_t, DowncallLinker::capture_state));    
+    __ z_lg(Z_ARG1, Address(Z_SP, locs.data_offset(StubLocations::CAPTURED_STATE_BUFFER)));
+    __ load_const_optimized(Z_ARG2, _captured_state_mask);
+    __ call(call_target_address);
+
+    if (should_save_return_value) {
+      out_reg_spiller.generate_fill(_masm, spill_offset);
+    }
+
+    __ block_comment("} save thread local");
+  }    
+
+  //////////////////////////////////////////////////////////////////////////////
+
+  Label L_after_safepoint_poll;
+  Label L_safepoint_poll_slow_path;
+  Label L_reguard;
+  Label L_after_reguard;
+
+  if (_needs_transition) {
+    __ block_comment("{ thread native2java");	  
+    __ set_thread_state(_thread_in_native_trans);
+
+    if (!UseSystemMemoryBarrier) {
+      __ z_fence(); // Order state change wrt. safepoint poll.
+    }
+
+    __ safepoint_poll(L_safepoint_poll_slow_path, tmp);
+
+    __ load_and_test_int(tmp, Address(Z_thread, JavaThread::suspend_flags_offset()));
+    __ z_brne(L_safepoint_poll_slow_path);    
+
+    __ bind(L_after_safepoint_poll);
+
+    // change thread state
+    __ set_thread_state(_thread_in_Java);
+
+    __ block_comment("reguard stack check");
+    __ load_and_test_int(tmp, Address(Z_thread, JavaThread::stack_guard_state_offset()));
+    __ z_bre(L_reguard);
+    __ bind(L_after_reguard);
+
+    __ reset_last_Java_frame();
+    __ block_comment("} thread native2java");
+  }
+  
+  __ pop_frame();
+  __ restore_return_pc();             // This is the way back to the caller.
+  __ z_br(Z_R14);  
+
+  //////////////////////////////////////////////////////////////////////////////
+
+  if (_needs_transition) {
+    __ block_comment("{ L_safepoint_poll_slow_path");
+    __ bind(L_safepoint_poll_slow_path);
+
+    if (should_save_return_value) {
+      // Need to save the native result registers around any runtime calls.
+      out_reg_spiller.generate_spill(_masm, spill_offset);
+    }
+
+      __ load_const_optimized(call_target_address, CAST_FROM_FN_PTR(uint64_t, JavaThread::check_special_condition_for_native_trans));
+      __ z_lr(Z_ARG1, Z_thread);
+      __ call(call_target_address);
+
+    if (should_save_return_value) {
+      out_reg_spiller.generate_fill(_masm, spill_offset);
+    }
+
+    __ z_bru(L_after_safepoint_poll);
+    __ block_comment("} L_safepoint_poll_slow_path");
+
+    //////////////////////////////////////////////////////////////////////////////
+    __ block_comment("{ L_reguard");
+    __ bind(L_reguard);
+
+    if (should_save_return_value) {
+      out_reg_spiller.generate_spill(_masm, spill_offset);
+    }
+
+    __ load_const_optimized(call_target_address, CAST_FROM_FN_PTR(uint64_t, SharedRuntime::reguard_yellow_pages));
+    __ call(call_target_address);
+
+    if (should_save_return_value) {
+      out_reg_spiller.generate_fill(_masm, spill_offset);
+    }
+
+    __ z_bru(L_after_reguard);
+
+    __ block_comment("} L_reguard");
+  }
+
+  //////////////////////////////////////////////////////////////////////////////
+
+  __ flush();
 }
diff --git a/src/hotspot/cpu/s390/foreignGlobals_s390.cpp b/src/hotspot/cpu/s390/foreignGlobals_s390.cpp
index d3a318536bd..c0cdb0dd8d3 100644
--- a/src/hotspot/cpu/s390/foreignGlobals_s390.cpp
+++ b/src/hotspot/cpu/s390/foreignGlobals_s390.cpp
@@ -1,5 +1,5 @@
 /*
- * Copyright (c) 2022, 2023, Oracle and/or its affiliates. All rights reserved.
+ * Copyright (c) 2022, Oracle and/or its affiliates. All rights reserved.
  * Copyright (c) 2020, Red Hat, Inc. All rights reserved.
  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
  *
@@ -23,34 +23,242 @@
  */
 
 #include "precompiled.hpp"
-#include "code/vmreg.hpp"
+#include "asm/macroAssembler.inline.hpp"
+#include "code/vmreg.inline.hpp"
+#include "runtime/jniHandles.hpp"
+#include "runtime/jniHandles.inline.hpp"
+#include "oops/typeArrayOop.inline.hpp"
+#include "oops/oopCast.inline.hpp"
 #include "prims/foreignGlobals.hpp"
-#include "utilities/debug.hpp"
+#include "prims/foreignGlobals.inline.hpp"
+#include "prims/vmstorage.hpp"
+#include "utilities/formatBuffer.hpp"
 
-class MacroAssembler;
+#define __ masm->
+
+bool ABIDescriptor::is_volatile_reg(Register reg) const {
+  return _integer_argument_registers.contains(reg)
+    || _integer_additional_volatile_registers.contains(reg);
+}
+
+bool ABIDescriptor::is_volatile_reg(FloatRegister reg) const {
+    return _float_argument_registers.contains(reg)
+        || _float_additional_volatile_registers.contains(reg);
+}
 
 bool ForeignGlobals::is_foreign_linker_supported() {
-  return false;
+  return true;
 }
 
 const ABIDescriptor ForeignGlobals::parse_abi_descriptor(jobject jabi) {
-  Unimplemented();
-  return {};
+  oop abi_oop = JNIHandles::resolve_non_null(jabi);
+  ABIDescriptor abi;
+
+  objArrayOop inputStorage = jdk_internal_foreign_abi_ABIDescriptor::inputStorage(abi_oop);
+  parse_register_array(inputStorage, StorageType::INTEGER, abi._integer_argument_registers, as_Register);
+  parse_register_array(inputStorage, StorageType::FLOAT, abi._float_argument_registers, as_FloatRegister);
+
+  objArrayOop outputStorage = jdk_internal_foreign_abi_ABIDescriptor::outputStorage(abi_oop);
+  parse_register_array(outputStorage, StorageType::INTEGER, abi._integer_return_registers, as_Register);
+  parse_register_array(outputStorage, StorageType::FLOAT, abi._float_return_registers, as_FloatRegister);
+
+  objArrayOop volatileStorage = jdk_internal_foreign_abi_ABIDescriptor::volatileStorage(abi_oop);
+  parse_register_array(volatileStorage, StorageType::INTEGER, abi._integer_additional_volatile_registers, as_Register);
+  parse_register_array(volatileStorage, StorageType::FLOAT, abi._float_additional_volatile_registers, as_FloatRegister);
+
+  abi._stack_alignment_bytes = jdk_internal_foreign_abi_ABIDescriptor::stackAlignment(abi_oop);
+  abi._shadow_space_bytes = jdk_internal_foreign_abi_ABIDescriptor::shadowSpace(abi_oop);
+
+  abi._scratch1 = parse_vmstorage(jdk_internal_foreign_abi_ABIDescriptor::scratch1(abi_oop));
+  abi._scratch2 = parse_vmstorage(jdk_internal_foreign_abi_ABIDescriptor::scratch2(abi_oop));
+
+  return abi;
 }
 
 int RegSpiller::pd_reg_size(VMStorage reg) {
-  Unimplemented();
-  return -1;
+  if (reg.type() == StorageType::INTEGER || reg.type() == StorageType::FLOAT) {
+    return 8;
+  }
+  return 0; // stack and BAD
 }
 
 void RegSpiller::pd_store_reg(MacroAssembler* masm, int offset, VMStorage reg) {
-  Unimplemented();
+  if (reg.type() == StorageType::INTEGER) {
+    __ z_stg(as_Register(reg), Address(Z_SP, offset));
+  } else if (reg.type() == StorageType::FLOAT) {
+    __ z_std(as_FloatRegister(reg), Address(Z_SP, offset));
+  } else {
+    // stack and BAD
+  }
 }
 
 void RegSpiller::pd_load_reg(MacroAssembler* masm, int offset, VMStorage reg) {
-  Unimplemented();
+  if (reg.type() == StorageType::INTEGER) {
+    __ z_lg(as_Register(reg), Address(Z_SP, offset));
+  } else if (reg.type() == StorageType::FLOAT) {
+    __ z_ld(as_FloatRegister(reg), Address(Z_SP, offset));
+  } else {
+    // stack and BAD
+  }
+}
+
+static int reg2offset(VMStorage vms, int stk_bias) {
+  assert(!vms.is_reg(), "wrong usage");
+  return vms.index_or_offset() + stk_bias;
+}
+
+static void move_reg64(MacroAssembler* masm, int out_stk_bias,
+                       VMStorage from_reg, VMStorage to_reg)
+{
+  int out_bias = 0;
+  switch (to_reg.type()) {
+    case StorageType::INTEGER:
+      //assert(to_reg.segment_mask() == REG64_MASK, "only moves to 64-bit registers supported");	    
+      if (to_reg.segment_mask() == REG64_MASK && from_reg.segment_mask() == REG32_MASK ) {
+        // see CCallingConventionRequiresIntsAsLongs
+        __ z_lgfr(as_Register(to_reg), as_Register(from_reg));
+      } else {
+       __ z_lgr(as_Register(to_reg), as_Register(from_reg));
+      }
+      break;
+    case StorageType::FLOAT:
+      // FP arguments can get passed in GP reg!
+      //assert(from_reg.segment_mask() == to_reg.segment_mask(), "sanity");
+      //assert(to_reg.segment_mask() == REG64_MASK, "only moves to 64-bit registers supported");	    
+#if 0
+      if (to_reg.segment_mask() == REG32_MASK ) {
+        __ z_st(as_Register(from_reg), Address(Z_SP, -8));
+        __ z_le(as_FloatRegister(to_reg), Address(Z_SP, -8));
+      } else {
+        __ z_stg(as_Register(from_reg), Address(Z_SP, -8));
+        __ z_ld(as_FloatRegister(to_reg), Address(Z_SP, -8));
+      }
+#endif
+      __ z_ldgr(as_FloatRegister(to_reg), as_Register(from_reg));
+      break;
+    case StorageType::STACK:
+      out_bias = out_stk_bias;  //fallthrough
+    case StorageType::FRAME_DATA: {
+      // Integer types always get a 64 bit slot in C.
+      //Register storeval = as_Register(from_reg);
+      if (from_reg.segment_mask() == REG32_MASK) {
+        // see CCallingConventionRequiresIntsAsLongs
+	//Register tmp = Z_tmp_2;
+	__ z_lgfr(as_Register(from_reg), as_Register(from_reg));
+        //storeval = tmp;
+      }
+      switch (to_reg.stack_size()) {
+        case 8: __ z_stg(as_Register(from_reg), Address(Z_SP, reg2offset(to_reg, out_bias)));break;
+        case 4: __ z_st(as_Register(from_reg), Address(Z_SP, reg2offset(to_reg, out_bias)));break;
+	default: ShouldNotReachHere();
+      }
+      break;
+     }
+  default: ShouldNotReachHere();
+  }
+}
+
+static void move_float(MacroAssembler* masm, int out_stk_bias,
+                       VMStorage from_reg, VMStorage to_reg) {
+  switch (to_reg.type()) {
+    case StorageType::INTEGER:
+
+      //assert(to_reg.segment_mask() == REG64_MASK, "only moves to 64-bit registers supported");	    
+      // FP arguments can get passed in GP reg!
+      //assert(from_reg.segment_mask() == to_reg.segment_mask(), "sanity");
+#if 0
+      if (from_reg.segment_mask() == REG32_MASK) {
+        __ z_ste(as_FloatRegister(from_reg), Address(Z_SP, -8));
+        __ z_l(as_Register(to_reg), Address(Z_SP, -8));
+      } else {
+        __ z_std(as_FloatRegister(from_reg), Address(Z_SP, -8));
+        __ z_lg(as_Register(to_reg), Address(Z_SP, -8));
+      }
+#endif 
+      __ z_lgdr(as_Register(to_reg), as_FloatRegister(from_reg));
+      break;
+    case StorageType::FLOAT:
+      //assert(to_reg.segment_mask() == REG64_MASK, "only moves to 64-bit registers supported");	    
+      __ z_ldr(as_FloatRegister(to_reg), as_FloatRegister(from_reg));
+      break;
+    case StorageType::STACK:
+      if (from_reg.segment_mask() == REG32_MASK) {
+        assert(to_reg.stack_size() == 4, "size should match");
+        // TODO: Check if AIX needs 4 Byte offset
+        __ z_ste(as_FloatRegister(from_reg), Address(Z_SP, reg2offset(to_reg, out_stk_bias)));
+      } else {
+        assert(to_reg.stack_size() == 8, "size should match");
+        __ z_std(as_FloatRegister(from_reg), Address(Z_SP, reg2offset(to_reg, out_stk_bias)));
+      }
+      break;
+    default: ShouldNotReachHere();
+  }
+}
+
+static void move_stack(MacroAssembler* masm, Register callerSP, int in_stk_bias, int out_stk_bias,
+                       VMStorage from_reg, VMStorage to_reg) {
+  int out_bias = 0;
+  Address from_addr(callerSP, reg2offset(from_reg, in_stk_bias));
+  switch (to_reg.type()) {
+    case StorageType::INTEGER:
+      //assert(to_reg.segment_mask() == REG64_MASK, "only moves to 64-bit registers supported");	    
+      switch (from_reg.stack_size()) {
+        //case 8: __ z_lg(as_Register(to_reg), Address(callerSP, reg2offset(from_reg, in_stk_bias))); break;
+        //case 4: __ z_l(as_Register(to_reg), Address(callerSP, reg2offset(from_reg, in_stk_bias))); break;
+	case 8: __ mem2reg_opt(as_Register(to_reg), from_addr, true);break;
+	case 4: __ mem2reg_opt(as_Register(to_reg), from_addr, false);break;
+        default: ShouldNotReachHere();
+      }
+      break;
+    case StorageType::FLOAT:
+      //assert(to_reg.segment_mask() == REG64_MASK, "only moves to 64-bit registers supported");	    
+      switch (from_reg.stack_size()) {
+       // case 8: __ z_ld(as_FloatRegister(to_reg), Address(callerSP, reg2offset(from_reg, in_stk_bias))); break;
+        //case 4: __ z_le(as_FloatRegister(to_reg), Address(callerSP, reg2offset(from_reg, in_stk_bias))); break;
+	case 8: __ mem2freg_opt(as_FloatRegister(to_reg), from_addr, true);break;
+	case 4: __ mem2freg_opt(as_FloatRegister(to_reg), from_addr, false);break;
+        default: ShouldNotReachHere();
+      }
+      break;
+    case StorageType::STACK:
+      out_bias = out_stk_bias; // fallthrough
+    case StorageType::FRAME_DATA: {
+      switch (from_reg.stack_size()) {
+        case 8: __ z_mvc(Address(Z_SP, reg2offset(to_reg, out_stk_bias)), from_addr, 8); break;
+        case 4: __ z_mvc(Address(Z_SP, reg2offset(to_reg, out_stk_bias + 4)), from_addr, 4); break;
+        default: ShouldNotReachHere();
+      }
+    } break;
+    default: ShouldNotReachHere();
+  }
 }
 
 void ArgumentShuffle::pd_generate(MacroAssembler* masm, VMStorage tmp, int in_stk_bias, int out_stk_bias, const StubLocations& locs) const {
-  Unimplemented();
+  Register callerSP = as_Register(tmp); // preset
+  for (int i = 0; i < _moves.length(); i++) {
+    Move move = _moves.at(i);
+    VMStorage from_reg = move.from;
+    VMStorage to_reg   = move.to;
+
+    // replace any placeholders
+    if (from_reg.type() == StorageType::PLACEHOLDER) {
+      from_reg = locs.get(from_reg);
+    }
+    if (to_reg.type() == StorageType::PLACEHOLDER) {
+      to_reg = locs.get(to_reg);
+    }
+
+    switch (from_reg.type()) {
+      case StorageType::INTEGER:
+        move_reg64(masm, out_stk_bias, from_reg, to_reg);
+        break;
+      case StorageType::FLOAT:
+        move_float(masm, out_stk_bias, from_reg, to_reg);
+        break;
+      case StorageType::STACK:
+        move_stack(masm, callerSP, in_stk_bias, out_stk_bias, from_reg, to_reg);
+        break;
+      default: ShouldNotReachHere();
+    }
+  }
 }
diff --git a/src/hotspot/cpu/s390/foreignGlobals_s390.hpp b/src/hotspot/cpu/s390/foreignGlobals_s390.hpp
index 8b86a2b06a6..394e22a26ab 100644
--- a/src/hotspot/cpu/s390/foreignGlobals_s390.hpp
+++ b/src/hotspot/cpu/s390/foreignGlobals_s390.hpp
@@ -24,6 +24,23 @@
 #ifndef CPU_S390_VM_FOREIGN_GLOBALS_S390_HPP
 #define CPU_S390_VM_FOREIGN_GLOBALS_S390_HPP
 
-class ABIDescriptor {};
+struct ABIDescriptor {
+  GrowableArray<Register> _integer_argument_registers;
+  GrowableArray<Register> _integer_return_registers;
+  GrowableArray<FloatRegister> _float_argument_registers;
+  GrowableArray<FloatRegister> _float_return_registers;
+
+  GrowableArray<Register> _integer_additional_volatile_registers;
+  GrowableArray<FloatRegister> _float_additional_volatile_registers;
+
+  int32_t _stack_alignment_bytes;
+  int32_t _shadow_space_bytes;
+
+  VMStorage _scratch1;
+  VMStorage _scratch2;
+
+  bool is_volatile_reg(Register reg) const;
+  bool is_volatile_reg(FloatRegister reg) const;
+};
 
 #endif // CPU_S390_VM_FOREIGN_GLOBALS_S390_HPP
diff --git a/src/hotspot/cpu/s390/frame_s390.cpp b/src/hotspot/cpu/s390/frame_s390.cpp
index 23547fa6617..68721183a5e 100644
--- a/src/hotspot/cpu/s390/frame_s390.cpp
+++ b/src/hotspot/cpu/s390/frame_s390.cpp
@@ -218,13 +218,32 @@ frame frame::sender_for_entry_frame(RegisterMap *map) const {
 }
 
 UpcallStub::FrameData* UpcallStub::frame_data_for_frame(const frame& frame) const {
-  ShouldNotCallThis();
-  return nullptr;
+  assert(frame.is_upcall_stub_frame(), "wrong frame");
+  // need unextended_sp here, since normal sp is wrong for interpreter callees
+  return reinterpret_cast<UpcallStub::FrameData*>(
+    reinterpret_cast<address>(frame.unextended_sp()) + in_bytes(_frame_data_offset));
 }
 
 bool frame::upcall_stub_frame_is_first() const {
-  ShouldNotCallThis();
-  return false;
+  assert(is_upcall_stub_frame(), "must be optimzed entry frame");
+  UpcallStub* blob = _cb->as_upcall_stub();
+  JavaFrameAnchor* jfa = blob->jfa_for_frame(*this);
+  return jfa->last_Java_sp() == NULL;
+}
+
+frame frame::sender_for_upcall_stub_frame(RegisterMap* map) const {
+  assert(map != NULL, "map must be set");
+  UpcallStub* blob = _cb->as_upcall_stub();
+  // Java frame called from C; skip all C frames and return top C
+  // frame of that chunk as the sender
+  JavaFrameAnchor* jfa = blob->jfa_for_frame(*this);
+  assert(!upcall_stub_frame_is_first(), "must have a frame anchor to go back to");
+  assert(jfa->last_Java_sp() > sp(), "must be above this frame on stack");
+  map->clear();
+  assert(map->include_argument_oops(), "should be set by clear");
+  frame fr(jfa->last_Java_sp(), jfa->last_Java_pc());
+
+  return fr;
 }
 
 frame frame::sender_for_interpreter_frame(RegisterMap *map) const {
diff --git a/src/hotspot/cpu/s390/frame_s390.inline.hpp b/src/hotspot/cpu/s390/frame_s390.inline.hpp
index dfa68940bac..adc7443ec11 100644
--- a/src/hotspot/cpu/s390/frame_s390.inline.hpp
+++ b/src/hotspot/cpu/s390/frame_s390.inline.hpp
@@ -358,6 +358,11 @@ inline frame frame::sender(RegisterMap* map) const {
   if (is_interpreted_frame()) {
     return sender_for_interpreter_frame(map);
   }
+
+  if (is_entry_frame())       return sender_for_entry_frame(map);
+  if (is_upcall_stub_frame()) return sender_for_upcall_stub_frame(map);
+  if (is_interpreted_frame()) return sender_for_interpreter_frame(map);
+
   assert(_cb == CodeCache::find_blob(pc()),"Must be the same");
   if (_cb != nullptr) return sender_for_compiled_frame(map);
 
diff --git a/src/hotspot/cpu/s390/methodHandles_s390.cpp b/src/hotspot/cpu/s390/methodHandles_s390.cpp
index aaccdbabb9e..6a384b1f2b6 100644
--- a/src/hotspot/cpu/s390/methodHandles_s390.cpp
+++ b/src/hotspot/cpu/s390/methodHandles_s390.cpp
@@ -349,7 +349,15 @@ address MethodHandles::generate_method_handle_interpreter_entry(MacroAssembler*
 
 void MethodHandles::jump_to_native_invoker(MacroAssembler* _masm, Register nep_reg, Register temp_target) {
   BLOCK_COMMENT("jump_to_native_invoker {");
-  __ should_not_reach_here();
+  assert(nep_reg != noreg, "required register");
+
+  // Load the invoker, as NEP -> .invoker
+  __ verify_oop(nep_reg);
+
+  __ z_lg(temp_target, Address(nep_reg, jdk_internal_foreign_abi_NativeEntryPoint::downcall_stub_address_offset_in_bytes()));
+
+  __ z_br(temp_target);
+
   BLOCK_COMMENT("} jump_to_native_invoker");
 }
 
@@ -387,6 +395,7 @@ void MethodHandles::generate_method_handle_dispatch(MacroAssembler* _masm,
   } else if (iid == vmIntrinsics::_linkToNative) {
     assert(for_compiler_entry, "only compiler entry is supported");
     jump_to_native_invoker(_masm, member_reg, temp1);
+    return;
   }
 
   // The method is a member invoker used by direct method handles.
diff --git a/src/hotspot/cpu/s390/vmstorage_s390.hpp b/src/hotspot/cpu/s390/vmstorage_s390.hpp
index 192159adc4c..a53082fef3f 100644
--- a/src/hotspot/cpu/s390/vmstorage_s390.hpp
+++ b/src/hotspot/cpu/s390/vmstorage_s390.hpp
@@ -29,8 +29,10 @@
 #include "asm/register.hpp"
 
 enum class StorageType : int8_t {
-  STACK = 0,
-  PLACEHOLDER = 1,
+  INTEGER = 0,
+  FLOAT = 1,
+  STACK = 2,
+  PLACEHOLDER = 3,
 // special locations used only by native code
   FRAME_DATA = PLACEHOLDER + 1,
   INVALID = -1
@@ -38,15 +40,68 @@ enum class StorageType : int8_t {
 
 // need to define this before constructing VMStorage (below)
 constexpr inline bool VMStorage::is_reg(StorageType type) {
-   return false;
+   return type == StorageType::INTEGER || type == StorageType::FLOAT;
 }
 constexpr inline StorageType VMStorage::stack_type() { return StorageType::STACK; }
 constexpr inline StorageType VMStorage::placeholder_type() { return StorageType::PLACEHOLDER; }
 constexpr inline StorageType VMStorage::frame_data_type() { return StorageType::FRAME_DATA; }
 
+// Needs to be consistent with PPC64Architecture.java.
+constexpr uint16_t REG32_MASK = 0b0000000000000001;
+constexpr uint16_t REG64_MASK = 0b0000000000000011;
+
+inline Register as_Register(VMStorage vms) {
+  assert(vms.type() == StorageType::INTEGER, "not the right type");
+  return ::as_Register(vms.index());
+}
+
+inline FloatRegister as_FloatRegister(VMStorage vms) {
+  assert(vms.type() == StorageType::FLOAT, "not the right type");
+  return ::as_FloatRegister(vms.index());
+}
+
+inline VMStorage as_VMStorage(Register reg, uint16_t segment_mask = REG64_MASK) {
+  return VMStorage::reg_storage(StorageType::INTEGER, segment_mask, reg->encoding());
+}
+
+inline VMStorage as_VMStorage(FloatRegister reg, uint16_t segment_mask = REG64_MASK) {
+  return VMStorage::reg_storage(StorageType::FLOAT, segment_mask, reg->encoding());
+}
+
 inline VMStorage as_VMStorage(VMReg reg, BasicType bt) {
+  if (reg->is_Register()) {
+    uint16_t segment_mask = 0;
+    switch (bt) {
+      case T_BOOLEAN:
+      case T_CHAR   :
+      case T_BYTE   :
+      case T_SHORT  :
+      case T_INT    : segment_mask = REG32_MASK; break;
+      default       : segment_mask = REG64_MASK; break;
+    }
+    return as_VMStorage(reg->as_Register(), segment_mask);
+  } else if (reg->is_FloatRegister()) {
+    // FP regs always use double format. However, we need the correct format for loads /stores.
+    return as_VMStorage(reg->as_FloatRegister(), (bt == T_FLOAT) ? REG32_MASK : REG64_MASK);
+  } else if (reg->is_stack()) {
+    uint16_t size = 0;
+    switch (bt) {
+      case T_BOOLEAN:
+      case T_CHAR   :
+      case T_BYTE   :
+      case T_SHORT  :
+      case T_INT    :
+      case T_FLOAT  : size = 4; break;
+      default       : size = 8; break;
+    }
+    return VMStorage(StorageType::STACK, size,
+                     checked_cast<uint16_t>(reg->reg2stack() * VMRegImpl::stack_slot_size));
+  } else if (!reg->is_valid()) {
+    return VMStorage::invalid();
+  }
+
   ShouldNotReachHere();
   return VMStorage::invalid();
 }
 
-#endif // CPU_S390_VMSTORAGE_S390_INLINE_HPP
\ No newline at end of file
+#endif // CPU_S390_VMSTORAGE_S390_INLINE_HPP
diff --git a/src/java.base/share/classes/jdk/internal/foreign/CABI.java b/src/java.base/share/classes/jdk/internal/foreign/CABI.java
index eee4ae67457..7eb5b8861ca 100644
--- a/src/java.base/share/classes/jdk/internal/foreign/CABI.java
+++ b/src/java.base/share/classes/jdk/internal/foreign/CABI.java
@@ -41,6 +41,7 @@ public enum CABI {
     WIN_AARCH_64,
     LINUX_PPC_64_LE,
     LINUX_RISCV_64,
+    LINUX_S390,
     FALLBACK,
     UNSUPPORTED;
 
@@ -81,7 +82,11 @@ public enum CABI {
                 if (OperatingSystem.isLinux()) {
                     return LINUX_RISCV_64;
                 }
-            }
+            } else if (arch.equals("s390x")) {
+                if (OperatingSystem.isLinux()) {
+                    return LINUX_S390;
+                }		    
+	    }
         } else if (FallbackLinker.isSupported()) {
             return FALLBACK; // fallback linker
         }
diff --git a/src/java.base/share/classes/jdk/internal/foreign/abi/AbstractLinker.java b/src/java.base/share/classes/jdk/internal/foreign/abi/AbstractLinker.java
index 268fb8def43..c5cf26ef0d7 100644
--- a/src/java.base/share/classes/jdk/internal/foreign/abi/AbstractLinker.java
+++ b/src/java.base/share/classes/jdk/internal/foreign/abi/AbstractLinker.java
@@ -32,6 +32,7 @@ import jdk.internal.foreign.abi.aarch64.windows.WindowsAArch64Linker;
 import jdk.internal.foreign.abi.fallback.FallbackLinker;
 import jdk.internal.foreign.abi.ppc64.linux.LinuxPPC64leLinker;
 import jdk.internal.foreign.abi.riscv64.linux.LinuxRISCV64Linker;
+import jdk.internal.foreign.abi.s390.linux.LinuxS390Linker;
 import jdk.internal.foreign.abi.x64.sysv.SysVx64Linker;
 import jdk.internal.foreign.abi.x64.windows.Windowsx64Linker;
 import jdk.internal.foreign.layout.AbstractLayout;
@@ -59,7 +60,8 @@ import java.util.Objects;
 public abstract sealed class AbstractLinker implements Linker permits LinuxAArch64Linker, MacOsAArch64Linker,
                                                                       SysVx64Linker, WindowsAArch64Linker,
                                                                       Windowsx64Linker, LinuxPPC64leLinker,
-                                                                      LinuxRISCV64Linker, FallbackLinker {
+                                                                      LinuxRISCV64Linker, LinuxS390Linker,
+								      FallbackLinker {
 
     public interface UpcallStubFactory {
         MemorySegment makeStub(MethodHandle target, Arena arena);
diff --git a/src/java.base/share/classes/jdk/internal/foreign/abi/SharedUtils.java b/src/java.base/share/classes/jdk/internal/foreign/abi/SharedUtils.java
index b9f1de7ed64..2820fdd7bd6 100644
--- a/src/java.base/share/classes/jdk/internal/foreign/abi/SharedUtils.java
+++ b/src/java.base/share/classes/jdk/internal/foreign/abi/SharedUtils.java
@@ -35,6 +35,7 @@ import jdk.internal.foreign.abi.aarch64.windows.WindowsAArch64Linker;
 import jdk.internal.foreign.abi.fallback.FallbackLinker;
 import jdk.internal.foreign.abi.ppc64.linux.LinuxPPC64leLinker;
 import jdk.internal.foreign.abi.riscv64.linux.LinuxRISCV64Linker;
+import jdk.internal.foreign.abi.s390.linux.LinuxS390Linker;
 import jdk.internal.foreign.abi.x64.sysv.SysVx64Linker;
 import jdk.internal.foreign.abi.x64.windows.Windowsx64Linker;
 import jdk.internal.vm.annotation.ForceInline;
@@ -239,6 +240,7 @@ public final class SharedUtils {
             case WIN_AARCH_64 -> WindowsAArch64Linker.getInstance();
             case LINUX_PPC_64_LE -> LinuxPPC64leLinker.getInstance();
             case LINUX_RISCV_64 -> LinuxRISCV64Linker.getInstance();
+	    case LINUX_S390 -> LinuxS390Linker.getInstance();
             case FALLBACK -> FallbackLinker.getInstance();
             case UNSUPPORTED -> throw new UnsupportedOperationException("Platform does not support native linker");
         };
diff --git a/src/java.base/share/classes/jdk/internal/foreign/abi/s390/S390Architecture.java b/src/java.base/share/classes/jdk/internal/foreign/abi/s390/S390Architecture.java
new file mode 100644
index 00000000000..b1e525a56d2
--- /dev/null
+++ b/src/java.base/share/classes/jdk/internal/foreign/abi/s390/S390Architecture.java
@@ -0,0 +1,148 @@
+/*
+ * Copyright (c) 2020, 2023, Oracle and/or its affiliates. All rights reserved.
+ * Copyright (c) 2023 SAP SE. All rights reserved.
+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
+ *
+ * This code is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License version 2 only, as
+ * published by the Free Software Foundation.  Oracle designates this
+ * particular file as subject to the "Classpath" exception as provided
+ * by Oracle in the LICENSE file that accompanied this code.
+ *
+ * This code is distributed in the hope that it will be useful, but WITHOUT
+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * version 2 for more details (a copy is included in the LICENSE file that
+ * accompanied this code).
+ *
+ * You should have received a copy of the GNU General Public License version
+ * 2 along with this work; if not, write to the Free Software Foundation,
+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
+ *
+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
+ * or visit www.oracle.com if you need additional information or have any
+ * questions.
+ */
+package jdk.internal.foreign.abi.s390;
+
+import jdk.internal.foreign.abi.ABIDescriptor;
+import jdk.internal.foreign.abi.Architecture;
+import jdk.internal.foreign.abi.StubLocations;
+import jdk.internal.foreign.abi.VMStorage;
+import jdk.internal.foreign.abi.s390.linux.TypeClass;
+
+public final class S390Architecture implements Architecture {
+    public static final Architecture INSTANCE = new S390Architecture();
+
+    // Needs to be consistent with vmstorage_s390.hpp.
+    public static final short REG32_MASK = 0b0000_0000_0000_0001;
+    public static final short REG64_MASK = 0b0000_0000_0000_0011;
+
+    private static final int INTEGER_REG_SIZE = 8;
+    private static final int FLOAT_REG_SIZE = 8;
+    private static final int STACK_SLOT_SIZE = 8;
+
+    @Override
+    public boolean isStackType(int cls) {
+        return cls == StorageType.STACK;
+    }
+
+    @Override
+    public int typeSize(int cls) {
+        switch (cls) {
+            case StorageType.INTEGER:
+		    return INTEGER_REG_SIZE;
+            case StorageType.FLOAT:
+		    return FLOAT_REG_SIZE;
+            // STACK is deliberately omitted
+        }
+
+        throw new IllegalArgumentException("Invalid Storage Class: " + cls);
+    }
+
+    public interface StorageType {
+        byte INTEGER = 0;
+        byte FLOAT = 1;
+        byte STACK = 2;
+        byte PLACEHOLDER = 3;
+    }
+
+    public static class Regs { // break circular dependency
+        public static final VMStorage r0 = integerRegister(0);
+        public static final VMStorage r1 = integerRegister(1);
+        public static final VMStorage r2 = integerRegister(2);
+        public static final VMStorage r3 = integerRegister(3);
+        public static final VMStorage r4 = integerRegister(4);
+        public static final VMStorage r5 = integerRegister(5);
+        public static final VMStorage r6 = integerRegister(6);
+        public static final VMStorage r7 = integerRegister(7);
+        public static final VMStorage r8 = integerRegister(8);
+        public static final VMStorage r9 = integerRegister(9);
+        public static final VMStorage r10 = integerRegister(10);
+        public static final VMStorage r11 = integerRegister(11);
+        public static final VMStorage r12 = integerRegister(12);
+        public static final VMStorage r13 = integerRegister(13);
+        public static final VMStorage r14 = integerRegister(14);
+        public static final VMStorage r15 = integerRegister(15);
+
+        public static final VMStorage f0 = floatRegister(0);
+        public static final VMStorage f1 = floatRegister(1);
+        public static final VMStorage f2 = floatRegister(2);
+        public static final VMStorage f3 = floatRegister(3);
+        public static final VMStorage f4 = floatRegister(4);
+        public static final VMStorage f5 = floatRegister(5);
+        public static final VMStorage f6 = floatRegister(6);
+        public static final VMStorage f7 = floatRegister(7);
+        public static final VMStorage f8 = floatRegister(8);
+        public static final VMStorage f9 = floatRegister(9);
+        public static final VMStorage f10 = floatRegister(10);
+        public static final VMStorage f11 = floatRegister(11);
+        public static final VMStorage f12 = floatRegister(12);
+        public static final VMStorage f13 = floatRegister(13);
+        public static final VMStorage f14 = floatRegister(14);
+        public static final VMStorage f15 = floatRegister(15);
+    }
+
+    private static VMStorage integerRegister(int index) {
+        return new VMStorage(StorageType.INTEGER, REG64_MASK, index, "r" + index);
+    }
+
+    private static VMStorage floatRegister(int index) {
+        return new VMStorage(StorageType.FLOAT, REG64_MASK, index, "v" + index);
+    }
+
+    public static VMStorage stackStorage(short size, int byteOffset) {
+        return new VMStorage(StorageType.STACK, size, byteOffset);
+    }
+
+    public static ABIDescriptor abiFor(VMStorage[] inputIntRegs,
+                                       VMStorage[] inputFloatRegs,
+                                       VMStorage[] outputIntRegs,
+                                       VMStorage[] outputFloatRegs,
+                                       VMStorage[] volatileIntRegs,
+                                       VMStorage[] volatileFloatRegs,
+                                       int stackAlignment,
+                                       int shadowSpace,
+                                       VMStorage scratch1, VMStorage scratch2) {
+        return new ABIDescriptor(
+            INSTANCE,
+            new VMStorage[][] {
+                inputIntRegs,
+                inputFloatRegs,
+            },
+            new VMStorage[][] {
+                outputIntRegs,
+                outputFloatRegs,
+            },
+            new VMStorage[][] {
+                volatileIntRegs,
+                volatileFloatRegs,
+            },
+            stackAlignment,
+            shadowSpace,
+            scratch1, scratch2,
+            StubLocations.TARGET_ADDRESS.storage(StorageType.PLACEHOLDER),
+            StubLocations.RETURN_BUFFER.storage(StorageType.PLACEHOLDER),
+            StubLocations.CAPTURED_STATE_BUFFER.storage(StorageType.PLACEHOLDER));
+    }
+}
diff --git a/src/java.base/share/classes/jdk/internal/foreign/abi/s390/linux/LinuxS390CallArranger.java b/src/java.base/share/classes/jdk/internal/foreign/abi/s390/linux/LinuxS390CallArranger.java
new file mode 100644
index 00000000000..08afe385aaf
--- /dev/null
+++ b/src/java.base/share/classes/jdk/internal/foreign/abi/s390/linux/LinuxS390CallArranger.java
@@ -0,0 +1,308 @@
+/*
+ * Copyright (c) 2022, 2023, Oracle and/or its affiliates. All rights reserved.
+ * Copyright (c) 2023 SAP SE. All rights reserved.
+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
+ *
+ * This code is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License version 2 only, as
+ * published by the Free Software Foundation.  Oracle designates this
+ * particular file as subject to the "Classpath" exception as provided
+ * by Oracle in the LICENSE file that accompanied this code.
+ *
+ * This code is distributed in the hope that it will be useful, but WITHOUT
+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * version 2 for more details (a copy is included in the LICENSE file that
+ * accompanied this code).
+ *
+ * You should have received a copy of the GNU General Public License version
+ * 2 along with this work; if not, write to the Free Software Foundation,
+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
+ *
+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
+ * or visit www.oracle.com if you need additional information or have any
+ * questions.
+ */
+package jdk.internal.foreign.abi.s390.linux;
+
+import java.lang.foreign.AddressLayout;
+import java.lang.foreign.FunctionDescriptor;
+import java.lang.foreign.GroupLayout;
+import java.lang.foreign.MemoryLayout;
+import java.lang.foreign.MemorySegment;
+import jdk.internal.foreign.abi.ABIDescriptor;
+import jdk.internal.foreign.abi.AbstractLinker.UpcallStubFactory;
+import jdk.internal.foreign.abi.Binding;
+import jdk.internal.foreign.abi.CallingSequence;
+import jdk.internal.foreign.abi.CallingSequenceBuilder;
+import jdk.internal.foreign.abi.DowncallLinker;
+import jdk.internal.foreign.abi.LinkerOptions;
+import jdk.internal.foreign.abi.UpcallLinker;
+import jdk.internal.foreign.abi.SharedUtils;
+import jdk.internal.foreign.abi.VMStorage;
+import jdk.internal.foreign.Utils;
+
+import java.lang.foreign.ValueLayout;
+import java.lang.invoke.MethodHandle;
+import java.lang.invoke.MethodType;
+import java.util.List;
+import java.util.Map;
+import java.util.Optional;
+
+import static jdk.internal.foreign.abi.s390.linux.TypeClass.*;
+import static jdk.internal.foreign.abi.s390.S390Architecture.*;
+import static jdk.internal.foreign.abi.s390.S390Architecture.Regs.*;
+
+/**
+ * For the S390 C ABI specifically, this class uses CallingSequenceBuilder
+ * to translate a C FunctionDescriptor into a CallingSequence, which can then be turned into a MethodHandle.
+ *
+ * This includes taking care of synthetic arguments like pointers to return buffers for 'in-memory' returns.
+ */
+public class LinuxS390CallArranger {
+
+    private static final int STACK_SLOT_SIZE = 8;
+    public static final int MAX_REGISTER_ARGUMENTS = 5;
+    public static final int MAX_FLOAT_REGISTER_ARGUMENTS = 4;
+
+    private static final ABIDescriptor CLinux = abiFor(
+        new VMStorage[] { r2, r3, r4, r5, r6, }, // GP input
+        new VMStorage[] { f0, f2, f4, f6 }, // FP intput
+        new VMStorage[] { r2, }, // GP output
+        new VMStorage[] { f0, }, // FP output
+        new VMStorage[] { r0, r1 }, // volatile GP (excluding argument registers)
+        new VMStorage[] { f1, f3, f5, f7 }, // volatile FP (excluding argument registers)
+        8, // Stack is always 8 byte aligned on S390
+        160, // ABI header
+        r0, r1 // scratch reg r & 2
+    );
+
+    public record Bindings(CallingSequence callingSequence, boolean isInMemoryReturn) {}
+
+    public static Bindings getBindings(MethodType mt, FunctionDescriptor cDesc, boolean forUpcall) {
+        return getBindings(mt, cDesc, forUpcall, LinkerOptions.empty());
+    }
+
+    public static Bindings getBindings(MethodType mt, FunctionDescriptor cDesc, boolean forUpcall, LinkerOptions options) {
+        CallingSequenceBuilder csb = new CallingSequenceBuilder(CLinux, forUpcall, options);
+
+        BindingCalculator argCalc = forUpcall ? new BoxBindingCalculator(true) : new UnboxBindingCalculator(true);
+        BindingCalculator retCalc = forUpcall ? new UnboxBindingCalculator(false) : new BoxBindingCalculator(false);
+
+        boolean returnInMemory = isInMemoryReturn(cDesc.returnLayout());
+        if (returnInMemory) {
+            Class<?> carrier = MemorySegment.class;
+            MemoryLayout layout =SharedUtils.C_POINTER;
+            csb.addArgumentBindings(carrier, layout, argCalc.getBindings(carrier, layout));
+        } else if (cDesc.returnLayout().isPresent()) {
+            Class<?> carrier = mt.returnType();
+            MemoryLayout layout = cDesc.returnLayout().get();
+            csb.setReturnBindings(carrier, layout, retCalc.getBindings(carrier, layout));
+        }
+
+        for (int i = 0; i < mt.parameterCount(); i++) {
+            Class<?> carrier = mt.parameterType(i);
+            MemoryLayout layout = cDesc.argumentLayouts().get(i);
+            csb.addArgumentBindings(carrier, layout, argCalc.getBindings(carrier, layout));
+        }
+
+        return new Bindings(csb.build(), returnInMemory);
+    }
+
+    public static  MethodHandle arrangeDowncall(MethodType mt, FunctionDescriptor cDesc, LinkerOptions options) {
+        Bindings bindings = getBindings(mt, cDesc, false, options);
+
+        MethodHandle handle = new DowncallLinker(CLinux, bindings.callingSequence).getBoundMethodHandle();
+
+        if (bindings.isInMemoryReturn) {
+            handle = SharedUtils.adaptDowncallForIMR(handle, cDesc, bindings.callingSequence);
+        }
+
+        return handle;
+    }
+
+    public static UpcallStubFactory arrangeUpcall(MethodType mt, FunctionDescriptor cDesc,
+		    LinkerOptions options) {
+        Bindings bindings = getBindings(mt, cDesc, true, options);
+
+        final boolean dropReturn = true; /* drop return, since we don't have bindings for it */
+        return SharedUtils.arrangeUpcallHelper(mt, bindings.isInMemoryReturn, dropReturn, CLinux,
+                bindings.callingSequence);
+    }
+
+    private static boolean isInMemoryReturn(Optional<MemoryLayout> returnLayout) {
+        return returnLayout
+            .filter(GroupLayout.class::isInstance)
+            .filter(layout -> layout instanceof GroupLayout)
+            .isPresent();
+    }
+
+    static class StorageCalculator {
+        private final boolean forArguments;
+
+        private final int[] nRegs = new int[] { 0, 0 };
+        private long stackOffset = 0;
+
+        public StorageCalculator(boolean forArguments) {
+            this.forArguments = forArguments;
+        }
+
+	VMStorage stackAlloc(long size, long alignment) {
+		long alignedStackOffset = Utils.alignUp(stackOffset, alignment);
+
+		short encodedSize = (short) size;
+		assert (encodedSize & 0xFFFF) == size;
+
+		VMStorage storage = stackStorage(encodedSize, (int) alignedStackOffset);
+		stackOffset = alignedStackOffset + size;
+		return storage;
+	}
+	VMStorage regAlloc(int type) {
+		int gpRegCnt = (type == StorageType.INTEGER) ? 1 : 0;
+		int fpRegCnt = (type == StorageType.FLOAT) ? 1 : 0;
+
+		// Use stack if not enough registers available.
+		if ((type == StorageType.FLOAT && (nRegs[StorageType.FLOAT] + fpRegCnt) > MAX_FLOAT_REGISTER_ARGUMENTS)
+				|| (type == StorageType.INTEGER && (nRegs[StorageType.INTEGER] + gpRegCnt) > MAX_REGISTER_ARGUMENTS)) return null;
+
+		VMStorage[] source = (forArguments ? CLinux.inputStorage : CLinux.outputStorage)[type];
+		VMStorage result = source[nRegs[type]];
+
+		nRegs[StorageType.INTEGER] += gpRegCnt;
+		nRegs[StorageType.FLOAT] += fpRegCnt;
+		return result;	    
+
+	}
+	 VMStorage getStorage(int type, boolean is32Bit) {
+            VMStorage reg = regAlloc(type);
+            if (reg != null) return reg;
+
+            VMStorage stack;
+            if (is32Bit) {
+                //stackAlloc(4, 4); // Skip first half of stack slot.
+                stack = stackAlloc(4, STACK_SLOT_SIZE);
+            } else {
+                stack = stackAlloc(8, STACK_SLOT_SIZE);
+            }
+            return stack;
+        }
+    }
+
+    abstract static class BindingCalculator {
+        protected final StorageCalculator storageCalculator;
+
+        protected BindingCalculator(boolean forArguments) {
+            this.storageCalculator = new LinuxS390CallArranger.StorageCalculator(forArguments);
+        }
+
+        abstract List<Binding> getBindings(Class<?> carrier, MemoryLayout layout);
+    }
+
+    // Compute recipe for transfering arguments / return values to C from Java.
+    static class UnboxBindingCalculator extends BindingCalculator {
+        UnboxBindingCalculator(boolean forArguments) {
+            super(forArguments);
+        }
+
+        @Override
+        List<Binding> getBindings(Class<?> carrier, MemoryLayout layout) {
+            TypeClass argumentClass = TypeClass.classifyLayout(layout);
+            Binding.Builder bindings = Binding.builder();
+            switch (argumentClass) {
+                case STRUCT_REGISTER -> {
+                    assert carrier == MemorySegment.class;
+                    VMStorage storage = storageCalculator.getStorage(StorageType.INTEGER, false);
+                    Class<?> type = SharedUtils.primitiveCarrierForSize(layout.byteSize(), false);
+                    bindings.bufferLoad(0, type)
+                            .vmStore(storage, type);			
+                }
+                case STRUCT_SFA -> {
+                    assert carrier == MemorySegment.class;
+                    VMStorage storage = storageCalculator.getStorage(StorageType.FLOAT, carrier == float.class);
+                    Class<?> type = SharedUtils.primitiveCarrierForSize(layout.byteSize(), false);
+                    bindings.bufferLoad(0, type)
+                            .vmStore(storage, type);			
+                }
+                case STRUCT_REFERENCE -> {
+                    assert carrier == MemorySegment.class;
+                    bindings.copy(layout)
+                            .unboxAddress();
+                    VMStorage storage = storageCalculator.getStorage(StorageType.INTEGER, false);
+                    bindings.vmStore(storage, long.class);
+                }		
+                case POINTER -> {
+                    VMStorage storage = storageCalculator.getStorage(StorageType.INTEGER, false);
+                    bindings.unboxAddress()
+                            .vmStore(storage, long.class);
+                }
+                case INTEGER -> {
+                    // ABI requires all int types to get extended to 64 bit.
+                    VMStorage storage = storageCalculator.getStorage(StorageType.INTEGER, false);
+                    bindings.vmStore(storage, carrier);
+                }
+                case FLOAT -> {
+                    VMStorage storage = storageCalculator.getStorage(StorageType.FLOAT, carrier == float.class);
+                    bindings.vmStore(storage, carrier);
+                }
+                default -> throw new UnsupportedOperationException("Unhandled class " + argumentClass);
+            }
+            return bindings.build();
+        }
+    }
+
+    // Compute recipe for transfering arguments / return values from C to Java.
+    static class BoxBindingCalculator extends BindingCalculator {
+        BoxBindingCalculator(boolean forArguments) {
+            super(forArguments);
+        }
+
+        @Override
+        List<Binding> getBindings(Class<?> carrier, MemoryLayout layout) {
+            TypeClass argumentClass = TypeClass.classifyLayout(layout); 
+            Binding.Builder bindings = Binding.builder();
+            switch (argumentClass) {
+                case STRUCT_REGISTER -> {
+                    assert carrier == MemorySegment.class;
+                    bindings.allocate(layout)
+                            .dup();
+                    VMStorage storage = storageCalculator.getStorage(StorageType.INTEGER, false);
+                    Class<?> type = SharedUtils.primitiveCarrierForSize(layout.byteSize(), false);
+                    bindings.vmLoad(storage, type)
+                            .bufferStore(0, type);			
+                }
+                case STRUCT_SFA -> {
+                    assert carrier == MemorySegment.class;
+                    bindings.allocate(layout)
+                            .dup();
+                    VMStorage storage = storageCalculator.getStorage(StorageType.FLOAT, carrier == float.class);
+                    Class<?> type = SharedUtils.primitiveCarrierForSize(layout.byteSize(), false);
+                    bindings.vmLoad(storage, type)
+                            .bufferStore(0, type);			
+                }
+                case STRUCT_REFERENCE -> {
+                    assert carrier == MemorySegment.class;
+                    VMStorage storage = storageCalculator.getStorage(StorageType.INTEGER, false);
+                    bindings.vmLoad(storage, long.class)
+                            .boxAddress(layout);
+                }
+                case POINTER -> {
+		    AddressLayout addressLayout = (AddressLayout) layout;	
+                    VMStorage storage = storageCalculator.getStorage(StorageType.INTEGER, false);
+                    bindings.vmLoad(storage, long.class)
+                            .boxAddressRaw(Utils.pointeeByteSize(addressLayout), Utils.pointeeByteAlign(addressLayout));
+                }
+                case INTEGER -> {
+                    // We could use carrier != long.class for BoxBindingCalculator, but C always uses 64 bit slots.
+                    VMStorage storage = storageCalculator.getStorage(StorageType.INTEGER, false);
+                    bindings.vmLoad(storage, carrier);
+                }
+                case FLOAT -> {
+                    VMStorage storage = storageCalculator.getStorage(StorageType.FLOAT, carrier == float.class);
+                    bindings.vmLoad(storage, carrier);
+                }
+                default -> throw new UnsupportedOperationException("Unhandled class " + argumentClass);
+            }
+            return bindings.build();
+        }
+    }
+}
diff --git a/src/java.base/share/classes/jdk/internal/foreign/abi/s390/linux/LinuxS390Linker.java b/src/java.base/share/classes/jdk/internal/foreign/abi/s390/linux/LinuxS390Linker.java
new file mode 100644
index 00000000000..187e9b76d31
--- /dev/null
+++ b/src/java.base/share/classes/jdk/internal/foreign/abi/s390/linux/LinuxS390Linker.java
@@ -0,0 +1,64 @@
+/*
+ * Copyright (c) 2022, 2023, Oracle and/or its affiliates. All rights reserved.
+ * Copyright (c) 2023 SAP SE. All rights reserved.
+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
+ *
+ * This code is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License version 2 only, as
+ * published by the Free Software Foundation.  Oracle designates this
+ * particular file as subject to the "Classpath" exception as provided
+ * by Oracle in the LICENSE file that accompanied this code.
+ *
+ * This code is distributed in the hope that it will be useful, but WITHOUT
+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * version 2 for more details (a copy is included in the LICENSE file that
+ * accompanied this code).
+ *
+ * You should have received a copy of the GNU General Public License version
+ * 2 along with this work; if not, write to the Free Software Foundation,
+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
+ *
+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
+ * or visit www.oracle.com if you need additional information or have any
+ * questions.
+ */
+package jdk.internal.foreign.abi.s390.linux;
+
+import jdk.internal.foreign.abi.AbstractLinker;
+import jdk.internal.foreign.abi.LinkerOptions;
+
+import java.lang.foreign.FunctionDescriptor;
+import java.lang.invoke.MethodHandle;
+import java.lang.invoke.MethodType;
+import java.nio.ByteOrder;
+
+public final class LinuxS390Linker extends AbstractLinker {
+
+    public static LinuxS390Linker getInstance() {
+        final class Holder {
+            private static final LinuxS390Linker INSTANCE = new LinuxS390Linker();
+        }
+
+        return Holder.INSTANCE;
+    }
+
+    private LinuxS390Linker() {
+        // Ensure there is only one instance
+    }
+
+    @Override
+    protected MethodHandle arrangeDowncall(MethodType inferredMethodType, FunctionDescriptor function, LinkerOptions options) {
+        return LinuxS390CallArranger.arrangeDowncall(inferredMethodType, function, options);
+    }
+
+    @Override
+    protected UpcallStubFactory arrangeUpcall(MethodType targetType, FunctionDescriptor function, LinkerOptions options) {
+        return LinuxS390CallArranger.arrangeUpcall(targetType, function, options);
+    }
+
+    @Override
+    protected ByteOrder linkerByteOrder() {
+        return ByteOrder.BIG_ENDIAN;
+    }
+}
diff --git a/src/java.base/share/classes/jdk/internal/foreign/abi/s390/linux/TypeClass.java b/src/java.base/share/classes/jdk/internal/foreign/abi/s390/linux/TypeClass.java
new file mode 100644
index 00000000000..7430d730000
--- /dev/null
+++ b/src/java.base/share/classes/jdk/internal/foreign/abi/s390/linux/TypeClass.java
@@ -0,0 +1,137 @@
+/*
+ * Copyright (c) 2022, 2023, Oracle and/or its affiliates. All rights reserved.
+ * Copyright (c) 2023 SAP SE. All rights reserved.
+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
+ *
+ * This code is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License version 2 only, as
+ * published by the Free Software Foundation.  Oracle designates this
+ * particular file as subject to the "Classpath" exception as provided
+ * by Oracle in the LICENSE file that accompanied this code.
+ *
+ * This code is distributed in the hope that it will be useful, but WITHOUT
+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * version 2 for more details (a copy is included in the LICENSE file that
+ * accompanied this code).
+ *
+ * You should have received a copy of the GNU General Public License version
+ * 2 along with this work; if not, write to the Free Software Foundation,
+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
+ *
+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
+ * or visit www.oracle.com if you need additional information or have any
+ * questions.
+ */
+package jdk.internal.foreign.abi.s390.linux;
+
+import java.lang.foreign.GroupLayout;
+import java.lang.foreign.MemoryLayout;
+import java.lang.foreign.MemorySegment;
+import java.lang.foreign.SequenceLayout;
+import java.lang.foreign.ValueLayout;
+import java.util.List;
+import java.util.ArrayList;
+
+public enum TypeClass {
+    STRUCT_REGISTER,
+    STRUCT_SFA, // Single Float Aggregate
+    STRUCT_REFERENCE,
+    POINTER,
+    INTEGER,
+    FLOAT;
+
+    private static final int MAX_AGGREGATE_REGS_SIZE = 1;
+
+    private static TypeClass classifyValueType(ValueLayout type) {
+        Class<?> carrier = type.carrier();
+        if (carrier == boolean.class || carrier == byte.class || carrier == char.class ||
+            carrier == short.class || carrier == int.class || carrier == long.class) {
+            return INTEGER;
+        } else if (carrier == float.class || carrier == double.class) {
+            return FLOAT;
+        } else if (carrier == MemorySegment.class) {
+            return POINTER;
+        } else {
+            throw new IllegalStateException("Cannot get here: " + carrier.getName());
+        }
+    }
+
+    private static boolean isRegisterAggregate(MemoryLayout type) {
+        return type.byteSize() <= MAX_AGGREGATE_REGS_SIZE * 8;
+    }
+
+    static List<MemoryLayout> scalarLayouts(GroupLayout gl) {
+        List<MemoryLayout> out = new ArrayList<>();
+        scalarLayoutsInternal(out, gl);
+        return out;
+    }
+
+    private static void scalarLayoutsInternal(List<MemoryLayout> out, GroupLayout gl) {
+        for (MemoryLayout member : gl.memberLayouts()) {
+            if (member instanceof GroupLayout memberGl) {
+                scalarLayoutsInternal(out, memberGl);
+            } else if (member instanceof SequenceLayout memberSl) {
+                for (long i = 0; i < memberSl.elementCount(); i++) {
+                    out.add(memberSl.elementLayout());
+                }
+            } else {
+                // padding or value layouts
+                out.add(member);
+            }
+        }
+    }
+
+    static boolean isSingleFloatAggregate(MemoryLayout type) {
+        List<MemoryLayout> scalarLayouts = scalarLayouts((GroupLayout) type);
+
+        final int numElements = scalarLayouts.size();
+        if (numElements > 1 || numElements == 0)
+            return false;
+
+        MemoryLayout baseType = scalarLayouts.get(0);
+
+        if (!(baseType instanceof ValueLayout))
+            return false;
+
+        TypeClass baseArgClass = classifyValueType((ValueLayout) baseType);
+        if (baseArgClass != FLOAT)
+           return false;
+
+        for (MemoryLayout elem : scalarLayouts) {
+            if (!(elem instanceof ValueLayout))
+                return false;
+
+            TypeClass argClass = classifyValueType((ValueLayout) elem);
+            if (elem.byteSize() != baseType.byteSize() ||
+                    elem.byteAlignment() != baseType.byteAlignment() ||
+                    baseArgClass != argClass) {
+                return false;
+            }
+        }
+
+        return true;
+    }
+
+    private static TypeClass classifyStructType(MemoryLayout layout) {
+
+        if (!isRegisterAggregate(layout)) {
+            return STRUCT_REFERENCE;
+        }
+	    
+        if (isSingleFloatAggregate(layout)) {
+            return TypeClass.STRUCT_SFA;
+        }
+        return TypeClass.STRUCT_REGISTER;
+    }
+
+    public static TypeClass classifyLayout(MemoryLayout type) {
+        if (type instanceof ValueLayout) {
+            return classifyValueType((ValueLayout) type);
+        } else if (type instanceof GroupLayout) {
+            return classifyStructType(type);
+        } else {
+            throw new IllegalArgumentException("Unsupported layout: " + type);
+        }
+    }
+}
diff --git a/test/hotspot/jtreg/gc/shenandoah/compiler/TestLinkToNativeRBP.java b/test/hotspot/jtreg/gc/shenandoah/compiler/TestLinkToNativeRBP.java
index a0dff95a23f..948b61cdb2c 100644
--- a/test/hotspot/jtreg/gc/shenandoah/compiler/TestLinkToNativeRBP.java
+++ b/test/hotspot/jtreg/gc/shenandoah/compiler/TestLinkToNativeRBP.java
@@ -28,7 +28,7 @@
  * @summary guarantee(loc != NULL) failed: missing saved register with native invoke
  *
  * @requires vm.flavor == "server"
- * @requires ((os.arch == "amd64" | os.arch == "x86_64") & sun.arch.data.model == "64") | os.arch == "aarch64" | os.arch == "ppc64le"
+ * @requires ((os.arch == "amd64" | os.arch == "x86_64") & sun.arch.data.model == "64") | os.arch == "aarch64" | os.arch == "ppc64le | os.arch == "s390x"
  * @requires vm.gc.Shenandoah
  *
  * @run main/othervm --enable-native-access=ALL-UNNAMED -XX:+UnlockDiagnosticVMOptions
diff --git a/test/jdk/java/foreign/callarranger/platform/PlatformLayouts.java b/test/jdk/java/foreign/callarranger/platform/PlatformLayouts.java
index 1646063fb08..4a181144ee6 100644
--- a/test/jdk/java/foreign/callarranger/platform/PlatformLayouts.java
+++ b/test/jdk/java/foreign/callarranger/platform/PlatformLayouts.java
@@ -306,4 +306,58 @@ public final class PlatformLayouts {
 
     }
 
+    /**
+     * This class defines layout constants modelling standard primitive types supported by the S390 ABI.
+     */
+    public static final class S390 {
+
+        private S390() {
+            //just the one
+        }
+
+        /**
+         * The {@code bool} native type.
+         */
+        public static final ValueLayout.OfBoolean C_BOOL = ValueLayout.JAVA_BOOLEAN;
+
+        /**
+         * The {@code char} native type.
+         */
+        public static final ValueLayout.OfByte C_CHAR = ValueLayout.JAVA_BYTE;
+
+        /**
+         * The {@code short} native type.
+         */
+        public static final ValueLayout.OfShort C_SHORT = ValueLayout.JAVA_SHORT;
+
+        /**
+         * The {@code int} native type.
+         */
+        public static final ValueLayout.OfInt C_INT = ValueLayout.JAVA_INT;
+
+        /**
+         * The {@code long} native type.
+         */
+        public static final ValueLayout.OfLong C_LONG = ValueLayout.JAVA_LONG;
+
+        /**
+         * The {@code long long} native type.
+         */
+        public static final ValueLayout.OfLong C_LONG_LONG = ValueLayout.JAVA_LONG;
+
+        /**
+         * The {@code float} native type.
+         */
+        public static final ValueLayout.OfFloat C_FLOAT = ValueLayout.JAVA_FLOAT;
+
+        /**
+         * The {@code double} native type.
+         */
+        public static final ValueLayout.OfDouble C_DOUBLE = ValueLayout.JAVA_DOUBLE;
+
+        /**
+         * The {@code T*} native type.
+         */
+        public static final AddressLayout C_POINTER = SharedUtils.C_POINTER;
+    }
 }
-- 
2.34.1

